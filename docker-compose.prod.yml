version: '3.8'

services:
  app:
    build:
      context: ./app
      dockerfile: Dockerfile.prod
    ports:
      - "80:80"
    environment:
      - NODE_ENV=production
    restart: unless-stopped
    
    # ヘルスチェック
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/"]
      interval: 30s
      timeout: 10s
      retries: 3

  # 将来的にLLMサービスを分離する場合の準備
  # llm-service:
  #   image: your-llm-service:latest
  #   ports:
  #     - "8000:8000"
  #   environment:
  #     - MODEL_NAME=your-model
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 4G
  #       reservations:
  #         memory: 2G
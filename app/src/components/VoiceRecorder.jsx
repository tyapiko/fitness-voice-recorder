import React, { useState, useEffect } from 'react';
import useSpeechRecognition from '../hooks/useSpeechRecognition';
import useLLM from '../hooks/useLLM';
import useIndexedDB from '../hooks/useIndexedDB';

const VoiceRecorder = ({ onRecordSaved, isLoading, setIsLoading }) => {
  const [recognizedText, setRecognizedText] = useState('');
  const [customExercises, setCustomExercises] = useState([]);
  const { isListening, startListening, stopListening } = useSpeechRecognition(setRecognizedText);
  const { processWithLLM } = useLLM();
  const { saveRecord, getCustomExercises } = useIndexedDB();

  // ã‚«ã‚¹ã‚¿ãƒ ç¨®ç›®ã‚’èª­ã¿è¾¼ã‚€
  useEffect(() => {
    const loadCustomExercises = async () => {
      try {
        const exercises = await getCustomExercises();
        setCustomExercises(exercises);
      } catch (error) {
        console.error('ã‚«ã‚¹ã‚¿ãƒ ç¨®ç›®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼:', error);
      }
    };
    loadCustomExercises();
  }, [getCustomExercises]);

  const handleRecord = () => {
    if (isListening) {
      stopListening();
    } else {
      setRecognizedText('');
      startListening();
    }
  };

  const handleSave = async () => {
    if (!recognizedText.trim()) return;

    setIsLoading(true);
    try {
      const structuredData = await processWithLLM(recognizedText, customExercises);
      
      // æ—¥ä»˜ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ãã®æ—¥ä»˜ã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°ç¾åœ¨æ—¥æ™‚
      let recordTimestamp = new Date();
      if (structuredData.date) {
        recordTimestamp = new Date(structuredData.date);
        // æ™‚åˆ»ã¯ç¾åœ¨æ™‚åˆ»ã‚’ä½¿ç”¨ï¼ˆæ—¥ä»˜ã®ã¿å¤‰æ›´ï¼‰
        const now = new Date();
        recordTimestamp.setHours(now.getHours(), now.getMinutes(), now.getSeconds(), now.getMilliseconds());
      }
      
      const record = {
        id: crypto.randomUUID(),
        timestamp: recordTimestamp,
        raw_input: recognizedText,
        exercises: structuredData.exercises || [],
        created_at: new Date(),
        updated_at: new Date()
      };

      await saveRecord(record);
      onRecordSaved(record);
      setRecognizedText('');
    } catch (error) {
      console.error('è¨˜éŒ²ä¿å­˜ã‚¨ãƒ©ãƒ¼:', error);
      alert('è¨˜éŒ²ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚');
    } finally {
      setIsLoading(false);
    }
  };

  const handleClear = () => {
    setRecognizedText('');
  };

  return (
    <div className="voice-section">
      <button 
        className={`record-button ${isListening ? 'recording' : ''}`}
        onClick={handleRecord}
        disabled={isLoading}
      >
        ğŸ¤ {isListening ? 'éŒ²éŸ³ä¸­...' : 'éŒ²éŸ³é–‹å§‹'}
      </button>

      {recognizedText && (
        <>
          <div className="recognized-text">
            <strong>èªè­˜ãƒ†ã‚­ã‚¹ãƒˆ:</strong>
            <p>{recognizedText}</p>
          </div>

          <div className="action-buttons">
            <button 
              className="btn btn-primary" 
              onClick={handleSave}
              disabled={isLoading}
            >
              {isLoading ? 'ä¿å­˜ä¸­...' : 'ä¿å­˜'}
            </button>
            <button 
              className="btn btn-secondary" 
              onClick={handleClear}
              disabled={isLoading}
            >
              ã‚¯ãƒªã‚¢
            </button>
          </div>
        </>
      )}
    </div>
  );
};

export default VoiceRecorder;